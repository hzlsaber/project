<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SIDA: Social Media Image Deepfake Detection</title>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Roboto', sans-serif;
            max-width: 800px;
            margin: auto;
            text-align: center;
            padding: 50px 20px;
        }

        h1 {
            font-size: 2.5rem; /* Reduced font size for title */
            font-weight: bold;
            margin-bottom: 20px;
        }

        .authors {
            font-size: 1.3rem; /* Increased font size for authors */
            line-height: 1.8;
            margin-bottom: 30px;
        }

        .abstract {
            text-align: left; /* Align text to the left */
            background-color: #f9f9f9; /* Light background color */
            border-left: 4px solid #444; /* Left border for visual separation */
            padding: 15px;
            margin-bottom: 30px;
            font-size: 1.1rem;
        }

        img {
            max-width: 100%; /* Ensure image is responsive */
            height: auto;
            margin: 20px 0; /* Adds spacing around the image */
        }

        .buttons {
            margin-top: 30px;
        }

        .button {
            display: inline-block;
            padding: 12px 25px;
            margin: 10px;
            font-size: 1.1rem;
            text-decoration: none;
            color: white;
            background-color: #444;
            border-radius: 5px;
            transition: background-color 0.3s;
        }

        .button:hover {
            background-color: #333;
        }

        .icon {
            margin-right: 5px;
        }
    </style>
</head>

<body>
    <h1>SIDA: Social Media Image Deepfake Detection, Localization and Explanation with Large Multimodal Model</h1>
    <div class="authors">
        Zhenglin Huang<sup>1</sup>, Jinwei Hu<sup>1</sup>, Xiangtai Li<sup>2</sup>, Yiwei He<sup>1</sup>, Baoyuan Wu<sup>3</sup>,<br>
        Xiaowei Huang<sup>1</sup>, Xingyu Zhao<sup>4</sup>, Bei Peng<sup>1</sup>, Guangliang Cheng<sup>1</sup><br>
        <small>1 University of Liverpool, UK, 2 Bytedance, 3 The Chinese University of Hong Kong, Shenzhen, Guangdong, China, 4 WMG, University of Warwick</small>
    </div>

    <div class="buttons">
        <a href="#" class="button">
            <span class="icon">üìÑ</span> Paper
        </a>
        <a href="#" class="button">
            <span class="icon">üìù</span> arXiv
        </a>
        <a href="#" class="button">
            <span class="icon">üé•</span> Video
        </a>
        <a href="#" class="button">
            <span class="icon">üíª</span> Code
        </a>
    </div>
    <!-- Image added below -->
    <figure>
        <img src="./images/image1.png" alt="An illustration of deepfake detection, localization, and explanation.">
        <figcaption>
            Existing deepfake methods (a-b) are limited to detection, localization, or both. In contrast, SIDA (c) offers a more comprehensive solution, capable of handling detection, localization, and explanation tasks.
        </figcaption>
    </figure>    
    <!-- Abstract Section -->
    <div class="abstract">
        <strong>Abstract:</strong>The rapid advancement of generative models in creating
        highly realistic images poses substantial risks for misinformation dissemination. For instance, a synthetic image,
        when shared on social media, can mislead extensive audiences and erode trust in digital content, resulting in severe
        repercussions. Despite some progress, academia has not yet
        created a large and diversified deepfake detection dataset
        for social media, nor has it devised an effective solution to
        address this issue. In this paper, we introduce the Social media Image Detection dataSet (SID-Set), which offers three
        key advantages: (1) extensive volume, featuring 300K AIgenerated/tampered and authentic images with comprehensive annotations, (2) broad diversity, encompassing fully
        synthetic and tampered images across various classes, and
        (3) elevated realism, with images that are predominantly indistinguishable from genuine ones through mere visual inspection. Furthermore, leveraging the exceptional capabilities of large multimodal models, we propose a new image
        deepfake detection, localization, and explanation framework, named SIDA (Social media Image Detection, localization, and explanation Assistant). SIDA not only discerns
        the authenticity of images, but also delineates tampered regions through mask prediction and provides textual explanations of the model‚Äôs judgment criteria. Compared with
        state-of-the-art deepfake detection models on SID-Set and
        other benchmarks, extensive experiments demonstrate that
        SIDA achieves superior performance among diversified settings. The code, model, and dataset will be released.
        
    </div>
</body>

</html>
